{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recovering Molar Mass Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming Gaussian Distribution\n",
    "In this cell, we assume the molar masses are normally distributed. Our goal is to take in any two of $M_n$, $M_w$, and the $PDI$ ($PDI=\\frac{M_w}{M_n}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can analytically solve the integral expressions for $M_n$ and $M_w$ to find the correct $\\sigma$ value for our Gaussian distribution, which reveals that $\\sigma = M_n(M_w - M_n)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# With numerical integration, we don't recover exact sigma, but the distribution is close\n",
    "x_max = 100\n",
    "N = 1e3\n",
    "sigma = 301.\n",
    "x = np.linspace(0, x_max, round(N)+1)\n",
    "y = N*np.exp(-(x-50.)**2/(2.*sigma))\n",
    "M_n = np.sum(np.multiply(x,y))/np.sum(y)\n",
    "# Notice if we replace the numerical integral with analytical form of M_w, we get exact agreement\n",
    "M_w = np.sum(y*x**2)/np.sum(y*x)# (M_n**2 + sigma)/M_n\n",
    "plt.plot(x, y, label='True Distribution')\n",
    "plt.xlim(0, 100.)\n",
    "plt.vlines(M_n, 0, N, 'C1', label='M_n')\n",
    "plt.vlines(M_w, 0, N, 'C2', label='M_w')\n",
    "\n",
    "def recovered_gauss_sigma(Mn, Mw):\n",
    "    return Mn * (Mw - Mn)\n",
    "\n",
    "def gauss(x, mu, sigma, N=1000):\n",
    "    return N * np.exp(-(x - mu)**2 / (2. * sigma))\n",
    "\n",
    "recovered_sig = recovered_gauss_sigma(M_n, M_w)\n",
    "\n",
    "print(f'M_n: {M_n}\\nM_w: {M_w}\\nRecovered sigma: {recovered_sig}\\nActual sigma: {sigma}')\n",
    "\n",
    "\n",
    "y2 = gauss(x, mu=M_n, sigma=recovered_sig, N=N)\n",
    "plt.plot(x,y2, ':', lw=3, color='k', label='Recovered Distribution')\n",
    "plt.legend()\n",
    "#plt.savefig('gaussian_mass_dist_true.svg')\n",
    "mse = np.mean((y2-y)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our error scales as a function of the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_vals = [1e2, 2e2, 3e2, 4e2, 5e2, 1e3, 5e3, 1e4, 5e4, 1e5, 5e5, 1e6, 5e6, 1e7]\n",
    "mse_vals = []\n",
    "sigma = 301.\n",
    "for N in N_vals:\n",
    "    N = round(N)\n",
    "    x = np.linspace(0, x_max, N+1)\n",
    "    y = N * np.exp(-(x - 50.)**2 / (2. * sigma))\n",
    "    M_n = np.sum(np.multiply(x, y)) / np.sum(y)\n",
    "    M_w = np.sum(y * x**2)/np.sum(y * x)# (M_n**2 +  sigma)/M_n\n",
    "    recovered_sigma = M_n * (M_w - M_n)\n",
    "    y2 = N * np.exp(-(x - 50.)**2 / (2. * recovered_sigma))\n",
    "    mse_vals.append(np.mean( (100.*(np.abs(y2 - y)/N)) ))\n",
    "print(mse_vals)\n",
    "plt.plot(np.log(N_vals), mse_vals, 'o')\n",
    "plt.xlabel('log($N$)')\n",
    "plt.ylabel('M%E')\n",
    "#plt.savefig('gaussian_mse.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assuming Weibull Distribution\n",
    "That worked, so now let's try with a [Weibull distribution](https://en.wikipedia.org/wiki/Weibull_distribution)\n",
    "The expression for a Webull distribution has two parameters, $k$ and $\\lambda$, which are the **shape** and **scale** paramters, respectively.\n",
    "It is: $f(x;\\lambda,k) = \\frac{k}{\\lambda}(\\frac{x}{\\lambda}^(k-1)e^{-(x/\\lambda)^k}$ for $x\\ge0$ and $0$ for $x<0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weibull distribution\n",
    "def weib(x, shape=1., scale=1., coeff=1.):\n",
    "    return coeff * ( shape / scale * (x / scale) ** (shape - 1) * np.exp(- (x / scale) ** shape) )\n",
    "x = np.linspace(0., 100., 101)\n",
    "scale = 40.\n",
    "shape = 2.\n",
    "plt.figure()\n",
    "plt.plot(x, weib(x, shape, scale, coeff=2000), label='True Distribution')\n",
    "y = weib(x, shape, scale)\n",
    "weib_M_n = np.sum(x*y) / np.sum(y)\n",
    "plt.axvline(x=weib_M_n, color=\"C1\", label=f'$M_n={weib_M_n:.4}$')\n",
    "weib_M_w = np.sum(x**2 * y) / np.sum(x*y)\n",
    "plt.axvline(x=weib_M_w, color=\"C2\", label=f'$M_w={weib_M_w:.4}$')\n",
    "\n",
    "plt.xlabel('Molar Mass')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "#plt.savefig('weibull_mass_dist_true.svg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the Gaussian, there is no analytic solution for the Weibull distribution's parameters. We can find the expression for how they relate but trying to solve leads to a transcendental expression for $k$ or $\\lambda$. However, we can just solve numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import gamma\n",
    "import scipy.optimize\n",
    "# expression for k, the shape factor ('x' here)\n",
    "# the point where this function reaches zero is the correct k value\n",
    "def f1(x, Mn, Mw):\n",
    "    return (2. * x * gamma(2./x)) / gamma(1./x)**2 - (Mw / Mn)\n",
    "\n",
    "def f2(Mn, k):\n",
    "    return(Mn * k / gamma(1./k))\n",
    "\n",
    "# if we *know* the k value, does our expression for lambda hold? (should be ~40)\n",
    "print('the predicted value of lambda with k=2 is:', weib_M_n * 2. / gamma(0.5), '(should be ~40)')\n",
    "# good\n",
    "\n",
    "xrange = np.linspace(0,4,101)\n",
    "plt.figure()\n",
    "plt.plot(xrange,f1(xrange,weib_M_n, weib_M_w), label=r'$\\frac{k^2 \\Gamma(\\frac{2+k}{k})}{\\Gamma(1/k)^2}$')\n",
    "plt.plot(xrange, np.zeros_like(xrange), label='$y=0$')\n",
    "plt.ylim(-0.5,1)\n",
    "plt.legend()\n",
    "plt.xlabel('$k$')\n",
    "plt.ylabel('$f(k)$')\n",
    "\n",
    "# try numeric solver\n",
    "a=scipy.optimize.root(f1, args=(weib_M_n, weib_M_w), x0=1.)\n",
    "recovered_k = a['x']\n",
    "print('recovered k:', recovered_k)\n",
    "# Now that we have the shape factor, plug it in to the other expression to solve for lambda\n",
    "# lambda = M_n * k / Gamma(1/k)\n",
    "recovered_lambda = f2(weib_M_n, recovered_k)\n",
    "print('recovered lambda:', recovered_lambda)\n",
    "plt.scatter(recovered_k, 0, color='k')\n",
    "plt.savefig('k_numerical_solution.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how that looks next to the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot recovered distro and compare\n",
    "x = np.linspace(0., 100., 101)\n",
    "scale = 40.\n",
    "shape = 2.\n",
    "plt.figure()\n",
    "plt.plot(x, weib(x, shape, scale, coeff=2000), label='True Distribution')\n",
    "plt.plot(x, weib(x, recovered_k, recovered_lambda, coeff=2000), label='Recovered Distribution', ls=':', color='k')\n",
    "y = weib(x, shape, scale)\n",
    "weib_M_n = np.sum(x*y) / np.sum(y)\n",
    "plt.axvline(x=weib_M_n, color=\"C1\", label=f'$M_n={weib_M_n:.4}$')\n",
    "weib_M_w = np.sum(x**2 * y) / np.sum(x*y)\n",
    "plt.axvline(x=weib_M_w, color=\"C2\", label=f'$M_w={weib_M_w:.4}$')\n",
    "\n",
    "plt.xlabel('Molar Mass')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.savefig('weibull_mass_dist_recovered.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we can package that up into a few functions for recovering our mass distro like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_k_expression(x, Mn, Mw):\n",
    "    return(2. * x * gamma(2./x)) / gamma(1./x)**2 - (Mw / Mn)\n",
    "\n",
    "def weibull_lambda_expression(Mn, k):\n",
    "    return(Mn * k / gamma(1./k))\n",
    "\n",
    "def recover_mass_dist(Mn=None, Mw=None, pdi=None, distribution='Gaussian'):\n",
    "    '''This function takes in two of the three quantities [Mn, Mw, PDI],\n",
    "       and fits either a Gaussian or Weibull distribution of molar masses to them.'''\n",
    "    if distribution.lower() != 'gaussian' and distribution.lower() != 'weibull':\n",
    "        raise(ValueError('Distribution must be either \"gaussian\" or \"weibull\".'))\n",
    "    pdi_arg_sum = sum([x is not None for x in [pdi, Mn, Mw]])\n",
    "    assert pdi_arg_sum >= 2, 'At least two of [pdi, M_n, M_w] must be given.'\n",
    "    if pdi_arg_sum == 3:\n",
    "        #special case, make sure that pdi = M_w / M_n\n",
    "        assert pdi - (Mw/Mn) < 1e-5, 'PDI value does not match M_n and M_w values.'\n",
    "    else:\n",
    "        # need to recover one of M_w or M_n or pdi\n",
    "        if Mn is None:\n",
    "            Mn = Mw / pdi\n",
    "        if Mw is None:\n",
    "            Mw = pdi * Mn\n",
    "        if pdi is None:\n",
    "            pdi = Mw / Mn\n",
    "    if distribution.lower() == 'gaussian':\n",
    "        mean = Mn\n",
    "        sigma = Mn * (Mw - Mn)\n",
    "        return lambda x: np.exp(-(x-Mn)**2 / (2. * sigma))\n",
    "    elif distribution.lower() == 'weibull':\n",
    "        # get the shape parameter\n",
    "        a = scipy.optimize.root(f1, args=(weib_M_n, weib_M_w), x0=1.)\n",
    "        recovered_k = a['x']\n",
    "        # get the scale parameter\n",
    "        recovered_lambda = f2(Mn, recovered_k)\n",
    "        return lambda x: ( recovered_k / recovered_lambda * (x / recovered_lambda) ** (recovered_k - 1) * np.exp(- (x / recovered_lambda) ** recovered_k) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0., 100., 101)\n",
    "scale = 40.\n",
    "shape = 2.\n",
    "f = recover_mass_dist(Mn=weib_M_n, Mw=weib_M_w, pdi=None, distribution='weibull')\n",
    "plt.plot(x, f(x), label='Recovered Distribution', color='k', ls=':')\n",
    "y = weib(x, shape, scale)\n",
    "weib_M_n = np.sum(x*y) / np.sum(y)\n",
    "plt.axvline(x=weib_M_n, color=\"C1\", label=f'$M_n={weib_M_n:.4}$')\n",
    "weib_M_w = np.sum(x**2 * y) / np.sum(x*y)\n",
    "plt.axvline(x=weib_M_w, color=\"C2\", label=f'$M_w={weib_M_w:.4}$')\n",
    "plt.plot(x, y, label='True Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Distributions on Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how these fit to real data. We have here some .csv files generated by [webplotdigitizer](https://apps.automeris.io/wpd/), from figures taken from Choupin, T. et al. \"Macromolecular modifications of ply(etherketoneketone) (PEKK) copolymer at the melting state,\" _Polymer Degradation and Stability_ **155** (2018), 103-110. This study examined the molar mass distribution of PEKK polymer at various times from 0 to 240 minutes of exposure to heat at 400$^{\\circ}$C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pekk_data_time_0 = np.genfromtxt('PEKK_No_Exposure.csv', delimiter=',')\n",
    "\n",
    "# clean web plot digitizer data a bit\n",
    "\n",
    "def filter_y(data_arr, high_cut=1e6, low_cut=5e-3):\n",
    "    indices = np.where(data_arr[:,1] < low_cut)\n",
    "    data_arr[indices, 1] = 0\n",
    "    return data_arr\n",
    "\n",
    "plt.figure()\n",
    "data = filter_y(pekk_data_time_0)\n",
    "\n",
    "x, y = np.log10(data[:,0]), data[:,1]\n",
    "plt.plot(x,y/np.sum(y), label='True Data')\n",
    "\n",
    "t0_Mn = np.sum(x*y) / np.sum(y)\n",
    "t0_Mw = np.sum(x*x*y) / np.sum(x*y)\n",
    "t0_pdi = t0_Mw / t0_Mn\n",
    "print('PDI:', t0_pdi)\n",
    "plt.axvline((t0_Mn), color='k', ls='-.', label='$M_n$')\n",
    "plt.axvline((t0_Mw), color='k', ls=':', label='$M_w$')\n",
    "\n",
    "print(t0_Mn)\n",
    "\n",
    "# Now recover the distribution with both methods\n",
    "# Gaussian\n",
    "t0_sig = recovered_gauss_sigma(Mn=(t0_Mn), Mw=(t0_Mw))\n",
    "print(t0_sig)\n",
    "gauss_y = gauss((x), mu=(t0_Mn), sigma=t0_sig, N = 1)\n",
    "plt.plot((x), gauss_y/np.sum(gauss_y), label='Gaussian', ls='--')\n",
    "\n",
    "# Weibull \n",
    "a=scipy.optimize.root(lambda x, y, z: f1((x), y, z), args=((t0_Mn), (t0_Mw)), x0=1.)\n",
    "print(a)\n",
    "recovered_k = a['x']\n",
    "print('recovered k:', recovered_k)\n",
    "# Now that we have the shape factor, plug it in to the other expression to solve for lambda\n",
    "# lambda = M_n * k / Gamma(1/k)\n",
    "recovered_lambda = f2((t0_Mn), recovered_k)\n",
    "print('recovered lambda:', recovered_lambda)\n",
    "weib_y = weib(x, recovered_k, recovered_lambda)\n",
    "plt.plot((x), weib_y/np.sum(weib_y), label='Weibull', ls='--')\n",
    "plt.xlabel('Molar Mass (log scale)')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but with data after 2 hours of heating\n",
    "pekk_data_time_240 = np.genfromtxt('240_Min.csv', delimiter=',')\n",
    "\n",
    "x, y = np.log10(pekk_data_time_240[:,0]), pekk_data_time_240[:,1]\n",
    "\n",
    "plt.plot(x, y/np.sum(y), label='True Data')\n",
    "\n",
    "t240_Mn = np.sum(x*y) / np.sum(y)\n",
    "t240_Mw = np.sum(x*x*y) / np.sum(x*y)\n",
    "\n",
    "gauss_f = recover_mass_dist(Mn=t240_Mn, Mw=t240_Mw, pdi=None, distribution='gaussian')\n",
    "weib_f = recover_mass_dist(Mn=t240_Mn, Mw=t240_Mw, pdi=None, distribution='weibull')\n",
    "\n",
    "plt.plot(x, gauss_f(x)/np.sum(gauss_f(x)), label='Gaussian', ls='--')\n",
    "plt.plot(x, weib_f(x)/np.sum(weib_f(x)), label='Weibull', ls='--')\n",
    "\n",
    "plt.axvline(t240_Mn, ls='-.', color='k', label='$M_n$')\n",
    "plt.axvline(t240_Mw, ls=':', color='k', label='$M_w$')\n",
    "\n",
    "plt.legend()\n",
    "# TODO: Why is the weibull so far off here?\n",
    "# TODO: Add in an error-checking function and check these directly\n",
    "# TODO: Digitize the rest of the timesteps from the paper and see how they all compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling from Recovered Distributions\n",
    "Now that we can recover our molar mass distributions, we can sample molar masses directly, which can tell us our polymer length to use in the simulation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
